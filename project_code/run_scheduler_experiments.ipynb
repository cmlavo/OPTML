{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9352f19e-c4e2-419f-bdb7-6f63cce7cec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is the script we use to generate our schedulers clean accuracy, adversarial accuracy, runtime and others.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the script we use to generate our schedulers clean accuracy, adversarial accuracy, runtime and others.\n",
    "we averaged multiple runs in our repport\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f83a55b-b69b-4a32-9634-231fecd67395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dbf237-9c79-4046-b08b-a00ccfdc2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..')))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import model.Models as Models\n",
    "import Defences as Defences\n",
    "import schedulers.Schedulers as Schedulers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Attacks import pgd_attack\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce2ffe6-51aa-4e92-9d35-1ff56de39b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset = \"CIFAR10\"\\nbatchsize = 200\\n\\nk_max = 7\\nepsilon = 255/8\\nepochs = 20\\nlr = 1e-4\\n\\ndef get_model():\\n    return Models.MediumConvNet().to(device) # See our Models.file, we also implemented ResNets and such\\nlr = 1e-4\\n\\ndef get_optimizer():\\n    return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyper parameters, feel free to experiment.\n",
    "The commented ones are the ones we used on CIFAR10\n",
    "\"\"\"\n",
    "\n",
    "# MNIST SetUp ------------------------\n",
    "device = \"cuda\"\n",
    "\n",
    "dataset = \"MNIST\" \n",
    "batchsize = 64 \n",
    "\n",
    "k_max = 20 \n",
    "epsilon = 0.3 \n",
    "epochs = 8 \n",
    "lr = 1e-3\n",
    "\n",
    "def get_model():\n",
    "    return Models.MediumConvNet().to(device) # See our Models.file, we also implemented ResNets and such\n",
    "\n",
    "def get_optimizer(model):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# CIFAR SetUp ------------------------\n",
    "\"\"\"\n",
    "dataset = \"CIFAR10\"\n",
    "batchsize = 200\n",
    "\n",
    "k_max = 7\n",
    "epsilon = 255/8\n",
    "epochs = 20\n",
    "lr = 1e-4\n",
    "\n",
    "def get_model():\n",
    "    return Models.MediumConvNet().to(device) # See our Models.file, we also implemented ResNets and such\n",
    "lr = 1e-4\n",
    "\n",
    "def get_optimizer():\n",
    "    return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1bd9405-cfaa-4d70-85eb-03334d8f66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size=64, dataset = dataset):\n",
    "    if dataset == \"MNIST\":\n",
    "        print(\"Loading MNIST data...\")\n",
    "        transform = transforms.ToTensor()\n",
    "        train_dataset = datasets.MNIST(root=\"../../project_code/data\", train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root=\"../../project_code/data\", train=False, download=True, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "        print(\"MNIST data loaded.\")\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    elif dataset == \"CIFAR10\":\n",
    "        \"\"\"Get CIFAR-10 data loaders with appropriate transforms\"\"\"\n",
    "        # CIFAR-10 specific transforms\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        \n",
    "        train_dataset = datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=transform_train)\n",
    "        test_dataset = datasets.CIFAR10(root=\"../data\", train=False, download=True, transform=transform_test)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=2)\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c888d02b-06d2-4627-91c6-26591efa2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on clean examples\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_loss /= test_total\n",
    "    test_acc = 100.0 * test_correct / test_total\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415d85d-6925-4388-9f54-fcb644f33983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_k_strategies(k_min=0, k_max=k_max, epsilon=epsilon, num_epochs=epochs, device=device, lr = lr):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(f\"Training on {device}\")\n",
    "    \n",
    "    train_loader, test_loader = get_data_loaders()\n",
    "    results = []\n",
    "    schedulers = {\n",
    "        \"Vanilla\": Schedulers.VanillaScheduler(),\n",
    "        \"Constant\": Schedulers.ConstantScheduler(k_min, k_max),\n",
    "        \"LinearUniformMix\": Schedulers.LinearUniformMixScheduler(k_min, k_max),\n",
    "        \"Exponential\": Schedulers.ExponentialScheduler(k_min, k_max),\n",
    "        \"Cyclic\": Schedulers.CyclicScheduler(k_min, k_max),\n",
    "        \"Random\": Schedulers.RandomScheduler(k_min, k_max),\n",
    "        \"Constant\": Schedulers.ConstantScheduler(k_min, k_max),\n",
    "    }\n",
    "    \n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    for name, scheduler in schedulers.items():\n",
    "        print(f\"\\nTraining with {name} scheduler...\")\n",
    "        \n",
    "        #model = Models.MediumConvNet().to(device)  # Using larger model\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        model = get_model()\n",
    "        optimizer = get_optimizer(model)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        Defences.train_with_adversarial_scheduler(\n",
    "            model, train_loader, test_loader, optimizer, criterion,\n",
    "            epsilon, scheduler, device, num_epochs=num_epochs, test_eval_rate=2\n",
    "        )\n",
    "        test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "        results.append({\n",
    "            \"strategy\": name,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy\": test_acc\n",
    "        })\n",
    "        # Save model after training\n",
    "        torch.save(model.state_dict(), f\"results/model_{name}.pth\")\n",
    "    # Save results to CSV\n",
    "    pd.DataFrame(results).to_csv(\"results/k_strategy_results.csv\", index=False)\n",
    "    print(\"\\nSummary of results:\")\n",
    "    print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28de5b19-18b0-4d1d-a6ed-e932a80fd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(strategies, device):\n",
    "    model_dict = {}\n",
    "    for name in strategies:\n",
    "        model = get_model()  \n",
    "        model.load_state_dict(torch.load(f\"results/model_{name}.pth\", map_location=device))\n",
    "        model.eval()\n",
    "        model_dict[name] = model\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def evaluate_strategies_on_attacks(model_dict, test_loader, device, epsilon=epsilon, k_list=[1,2,4,8,16]):\n",
    "    results = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for strategy, model in model_dict.items():\n",
    "        # Clean accuracy\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        clean_acc = 100.0 * correct / total\n",
    "\n",
    "        # Adversarial accuracy for each k\n",
    "        for k in k_list:\n",
    "            correct_adv = 0\n",
    "            total_adv = 0\n",
    "            confidences = []\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                adv_images, _ = pgd_attack(images, labels, model, criterion, epsilon, k, device)\n",
    "                outputs = model(adv_images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_adv += labels.size(0)\n",
    "                correct_adv += (predicted == labels).sum().item()\n",
    "                # Mean confidence on correct predictions\n",
    "                for i in range(labels.size(0)):\n",
    "                    confidences.append(probs[i, predicted[i]].item())\n",
    "            adv_acc = 100.0 * correct_adv / total_adv\n",
    "            mean_conf = float(np.mean(confidences)) if confidences else 0.0\n",
    "            results.append({\n",
    "                \"strategy\": strategy,\n",
    "                \"k\": k,\n",
    "                \"clean_acc\": clean_acc,\n",
    "                \"adv_acc\": adv_acc,\n",
    "                \"mean_confidence\": mean_conf\n",
    "            })\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"results/adversarial_evaluation.csv\", index=False)\n",
    "    print(\"\\nAdversarial evaluation results:\")\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a668ef-efab-4546-b4c9-87ab0ab0a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Loading MNIST data...\n",
      "MNIST data loaded.\n",
      "\n",
      "Training with Vanilla scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.2780, Train Acc: 91.28%\n",
      "Epoch 2/8 | Train Loss: 0.0875, Train Acc: 97.48% | Test Loss: 0.0351, Test Acc: 98.87%\n",
      "Test Adv Loss (k=7): 7.6994, Test Adv Acc: 0.58%\n",
      "Epoch 3/8 | Train Loss: 0.0597, Train Acc: 98.30%\n",
      "Epoch 4/8 | Train Loss: 0.0495, Train Acc: 98.56% | Test Loss: 0.0387, Test Acc: 98.65%\n",
      "Test Adv Loss (k=7): 10.4333, Test Adv Acc: 0.56%\n",
      "Epoch 5/8 | Train Loss: 0.0439, Train Acc: 98.73%\n",
      "Epoch 6/8 | Train Loss: 0.0349, Train Acc: 98.99% | Test Loss: 0.0252, Test Acc: 99.26%\n",
      "Test Adv Loss (k=7): 12.2586, Test Adv Acc: 0.01%\n",
      "Epoch 7/8 | Train Loss: 0.0307, Train Acc: 99.08%\n",
      "Epoch 8/8 | Train Loss: 0.0263, Train Acc: 99.21% | Test Loss: 0.0237, Test Acc: 99.24%\n",
      "Test Adv Loss (k=7): 14.3857, Test Adv Acc: 0.09%\n",
      "Training time (without eval): 1 min 0.05 sec\n",
      "\n",
      "Training with Constant scheduler...\n",
      "Epoch 1/8 | Train Loss: 2.3022, Train Acc: 11.01%\n",
      "Epoch 2/8 | Train Loss: 2.3015, Train Acc: 11.24% | Test Loss: 2.3011, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3011, Test Adv Acc: 11.35%\n",
      "Epoch 3/8 | Train Loss: 2.3014, Train Acc: 11.24%\n",
      "Epoch 4/8 | Train Loss: 2.3014, Train Acc: 11.24% | Test Loss: 2.3010, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3010, Test Adv Acc: 11.35%\n",
      "Epoch 5/8 | Train Loss: 2.3013, Train Acc: 11.24%\n",
      "Epoch 6/8 | Train Loss: 2.3013, Train Acc: 11.24% | Test Loss: 2.3011, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3011, Test Adv Acc: 11.35%\n",
      "Epoch 7/8 | Train Loss: 2.3013, Train Acc: 11.24%\n",
      "Epoch 8/8 | Train Loss: 2.3013, Train Acc: 11.24% | Test Loss: 2.3010, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3010, Test Adv Acc: 11.35%\n",
      "Training time (without eval): 3 min 44.41 sec\n",
      "\n",
      "Training with LinearUniformMix scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.2883, Train Acc: 90.94%\n",
      "Epoch 2/8 | Train Loss: 0.7554, Train Acc: 75.12% | Test Loss: 0.0485, Test Acc: 98.49%\n",
      "Test Adv Loss (k=7): 0.8485, Test Adv Acc: 71.29%\n",
      "Epoch 3/8 | Train Loss: 0.5606, Train Acc: 82.00%\n",
      "Epoch 4/8 | Train Loss: 0.4080, Train Acc: 87.13% | Test Loss: 0.0488, Test Acc: 98.35%\n",
      "Test Adv Loss (k=7): 0.3231, Test Adv Acc: 89.31%\n",
      "Epoch 5/8 | Train Loss: 0.3240, Train Acc: 90.01%\n",
      "Epoch 6/8 | Train Loss: 0.2712, Train Acc: 91.65% | Test Loss: 0.0415, Test Acc: 98.67%\n",
      "Test Adv Loss (k=7): 0.2182, Test Adv Acc: 92.51%\n",
      "Epoch 7/8 | Train Loss: 0.2393, Train Acc: 92.61%\n",
      "Epoch 8/8 | Train Loss: 0.2134, Train Acc: 93.28% | Test Loss: 0.0379, Test Acc: 98.69%\n",
      "Test Adv Loss (k=7): 0.1747, Test Adv Acc: 94.16%\n",
      "Training time (without eval): 1 min 37.46 sec\n",
      "\n",
      "Training with Exponential scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.3073, Train Acc: 90.38%\n",
      "Epoch 2/8 | Train Loss: 0.0988, Train Acc: 97.16% | Test Loss: 0.0374, Test Acc: 98.79%\n",
      "Test Adv Loss (k=7): 7.7242, Test Adv Acc: 0.13%\n",
      "Epoch 3/8 | Train Loss: 0.7340, Train Acc: 76.40%\n",
      "Epoch 4/8 | Train Loss: 0.4340, Train Acc: 86.66% | Test Loss: 0.0475, Test Acc: 98.47%\n",
      "Test Adv Loss (k=7): 0.3492, Test Adv Acc: 88.25%\n",
      "Epoch 5/8 | Train Loss: 0.3187, Train Acc: 90.26%\n",
      "Epoch 6/8 | Train Loss: 0.2722, Train Acc: 91.75% | Test Loss: 0.0395, Test Acc: 98.66%\n",
      "Test Adv Loss (k=7): 0.2037, Test Adv Acc: 93.29%\n",
      "Epoch 7/8 | Train Loss: 0.2325, Train Acc: 93.05%\n",
      "Epoch 8/8 | Train Loss: 0.2030, Train Acc: 93.77% | Test Loss: 0.0347, Test Acc: 98.78%\n",
      "Test Adv Loss (k=7): 0.1508, Test Adv Acc: 95.06%\n",
      "Training time (without eval): 1 min 33.59 sec\n",
      "\n",
      "Training with Cyclic scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.7856, Train Acc: 74.03%\n",
      "Epoch 2/8 | Train Loss: 0.8271, Train Acc: 73.31% | Test Loss: 0.0927, Test Acc: 97.59%\n",
      "Test Adv Loss (k=7): 0.4148, Test Adv Acc: 86.19%\n",
      "Epoch 3/8 | Train Loss: 0.4693, Train Acc: 85.47%\n",
      "Epoch 4/8 | Train Loss: 0.2390, Train Acc: 92.85% | Test Loss: 0.0467, Test Acc: 98.54%\n",
      "Test Adv Loss (k=7): 0.2720, Test Adv Acc: 90.86%\n",
      "Epoch 5/8 | Train Loss: 0.3104, Train Acc: 90.61%\n",
      "Epoch 6/8 | Train Loss: 0.2491, Train Acc: 92.49% | Test Loss: 0.0468, Test Acc: 98.60%\n",
      "Test Adv Loss (k=7): 0.1711, Test Adv Acc: 94.34%\n",
      "Epoch 7/8 | Train Loss: 0.1974, Train Acc: 94.10%\n",
      "Epoch 8/8 | Train Loss: 0.1897, Train Acc: 94.36% | Test Loss: 0.0323, Test Acc: 98.91%\n",
      "Test Adv Loss (k=7): 0.1404, Test Adv Acc: 95.44%\n",
      "Training time (without eval): 2 min 11.72 sec\n",
      "\n",
      "Training with Random scheduler...\n",
      "Epoch 1/8 | Train Loss: 2.3021, Train Acc: 10.97%\n",
      "Epoch 2/8 | Train Loss: 2.3014, Train Acc: 11.24% | Test Loss: 2.3010, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3010, Test Adv Acc: 11.35%\n",
      "Epoch 3/8 | Train Loss: 2.3014, Train Acc: 11.24%\n",
      "Epoch 4/8 | Train Loss: 2.3013, Train Acc: 11.24% | Test Loss: 2.3011, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3011, Test Adv Acc: 11.35%\n",
      "Epoch 5/8 | Train Loss: 2.3013, Train Acc: 11.24%\n",
      "Epoch 6/8 | Train Loss: 2.3013, Train Acc: 11.24% | Test Loss: 2.3011, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3011, Test Adv Acc: 11.35%\n",
      "Epoch 7/8 | Train Loss: 2.3013, Train Acc: 11.24%\n",
      "Epoch 8/8 | Train Loss: 2.3013, Train Acc: 11.24% | Test Loss: 2.3010, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3010, Test Adv Acc: 11.35%\n",
      "Training time (without eval): 2 min 22.93 sec\n",
      "\n",
      "Summary of results:\n",
      "           strategy  test_loss  test_accuracy\n",
      "0           Vanilla   0.023677          99.24\n",
      "1          Constant   2.301013          11.35\n",
      "2  LinearUniformMix   0.037867          98.69\n",
      "3       Exponential   0.034675          98.78\n",
      "4            Cyclic   0.032280          98.91\n",
      "5            Random   2.301038          11.35\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate results\n",
    "\"\"\"\n",
    "run_all_k_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1605691e-afcf-4146-b70f-56f18ef26bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data...\n",
      "MNIST data loaded.\n",
      "\n",
      "Adversarial evaluation results:\n",
      "            strategy   k  clean_acc  adv_acc  mean_confidence\n",
      "0            Vanilla   1      99.24    15.66         0.714379\n",
      "1            Vanilla   2      99.24     2.61         0.863207\n",
      "2            Vanilla   4      99.24     0.28         0.951862\n",
      "3            Vanilla   8      99.24     0.04         0.978362\n",
      "4            Vanilla  16      99.24     0.00         0.984970\n",
      "5           Constant   1      11.35    11.35         0.113462\n",
      "6           Constant   2      11.35    11.35         0.113462\n",
      "7           Constant   4      11.35    11.35         0.113462\n",
      "8           Constant   8      11.35    11.35         0.113462\n",
      "9           Constant  16      11.35    11.35         0.113462\n",
      "10            Linear   1      98.81    96.17         0.966872\n",
      "11            Linear   2      98.81    95.62         0.964467\n",
      "12            Linear   4      98.81    95.31         0.962138\n",
      "13            Linear   8      98.81    95.00         0.961116\n",
      "14            Linear  16      98.81    94.87         0.960150\n",
      "15  LinearUniformMix   1      98.69    95.80         0.962290\n",
      "16  LinearUniformMix   2      98.69    95.18         0.958389\n",
      "17  LinearUniformMix   4      98.69    94.56         0.955690\n",
      "18  LinearUniformMix   8      98.69    94.18         0.953208\n",
      "19  LinearUniformMix  16      98.69    93.99         0.951603\n",
      "20       Exponential   1      98.78    96.25         0.972100\n",
      "21       Exponential   2      98.78    95.84         0.969138\n",
      "22       Exponential   4      98.78    95.44         0.967560\n",
      "23       Exponential   8      98.78    95.07         0.965190\n",
      "24       Exponential  16      98.78    94.98         0.965058\n",
      "25            Cyclic   1      98.91    96.69         0.972485\n",
      "26            Cyclic   2      98.91    96.11         0.968564\n",
      "27            Cyclic   4      98.91    95.79         0.966761\n",
      "28            Cyclic   8      98.91    95.50         0.965473\n",
      "29            Cyclic  16      98.91    95.40         0.964958\n",
      "30            Random   1      11.35    11.35         0.112960\n",
      "31            Random   2      11.35    11.35         0.112960\n",
      "32            Random   4      11.35    11.35         0.112960\n",
      "33            Random   8      11.35    11.35         0.112960\n",
      "34            Random  16      11.35    11.35         0.112960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>k</th>\n",
       "      <th>clean_acc</th>\n",
       "      <th>adv_acc</th>\n",
       "      <th>mean_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1</td>\n",
       "      <td>99.24</td>\n",
       "      <td>15.66</td>\n",
       "      <td>0.714379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>2</td>\n",
       "      <td>99.24</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.863207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>4</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.951862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>8</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.978362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>16</td>\n",
       "      <td>99.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.984970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Constant</td>\n",
       "      <td>1</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.113462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Constant</td>\n",
       "      <td>2</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.113462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Constant</td>\n",
       "      <td>4</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.113462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Constant</td>\n",
       "      <td>8</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.113462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Constant</td>\n",
       "      <td>16</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.113462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear</td>\n",
       "      <td>1</td>\n",
       "      <td>98.81</td>\n",
       "      <td>96.17</td>\n",
       "      <td>0.966872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear</td>\n",
       "      <td>2</td>\n",
       "      <td>98.81</td>\n",
       "      <td>95.62</td>\n",
       "      <td>0.964467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear</td>\n",
       "      <td>4</td>\n",
       "      <td>98.81</td>\n",
       "      <td>95.31</td>\n",
       "      <td>0.962138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Linear</td>\n",
       "      <td>8</td>\n",
       "      <td>98.81</td>\n",
       "      <td>95.00</td>\n",
       "      <td>0.961116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Linear</td>\n",
       "      <td>16</td>\n",
       "      <td>98.81</td>\n",
       "      <td>94.87</td>\n",
       "      <td>0.960150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>1</td>\n",
       "      <td>98.69</td>\n",
       "      <td>95.80</td>\n",
       "      <td>0.962290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>2</td>\n",
       "      <td>98.69</td>\n",
       "      <td>95.18</td>\n",
       "      <td>0.958389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>4</td>\n",
       "      <td>98.69</td>\n",
       "      <td>94.56</td>\n",
       "      <td>0.955690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>8</td>\n",
       "      <td>98.69</td>\n",
       "      <td>94.18</td>\n",
       "      <td>0.953208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>16</td>\n",
       "      <td>98.69</td>\n",
       "      <td>93.99</td>\n",
       "      <td>0.951603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>1</td>\n",
       "      <td>98.78</td>\n",
       "      <td>96.25</td>\n",
       "      <td>0.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>98.78</td>\n",
       "      <td>95.84</td>\n",
       "      <td>0.969138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>98.78</td>\n",
       "      <td>95.44</td>\n",
       "      <td>0.967560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>8</td>\n",
       "      <td>98.78</td>\n",
       "      <td>95.07</td>\n",
       "      <td>0.965190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>16</td>\n",
       "      <td>98.78</td>\n",
       "      <td>94.98</td>\n",
       "      <td>0.965058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>1</td>\n",
       "      <td>98.91</td>\n",
       "      <td>96.69</td>\n",
       "      <td>0.972485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>2</td>\n",
       "      <td>98.91</td>\n",
       "      <td>96.11</td>\n",
       "      <td>0.968564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>4</td>\n",
       "      <td>98.91</td>\n",
       "      <td>95.79</td>\n",
       "      <td>0.966761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>8</td>\n",
       "      <td>98.91</td>\n",
       "      <td>95.50</td>\n",
       "      <td>0.965473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>16</td>\n",
       "      <td>98.91</td>\n",
       "      <td>95.40</td>\n",
       "      <td>0.964958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.112960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Random</td>\n",
       "      <td>2</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.112960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Random</td>\n",
       "      <td>4</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.112960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random</td>\n",
       "      <td>8</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.112960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Random</td>\n",
       "      <td>16</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.112960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            strategy   k  clean_acc  adv_acc  mean_confidence\n",
       "0            Vanilla   1      99.24    15.66         0.714379\n",
       "1            Vanilla   2      99.24     2.61         0.863207\n",
       "2            Vanilla   4      99.24     0.28         0.951862\n",
       "3            Vanilla   8      99.24     0.04         0.978362\n",
       "4            Vanilla  16      99.24     0.00         0.984970\n",
       "5           Constant   1      11.35    11.35         0.113462\n",
       "6           Constant   2      11.35    11.35         0.113462\n",
       "7           Constant   4      11.35    11.35         0.113462\n",
       "8           Constant   8      11.35    11.35         0.113462\n",
       "9           Constant  16      11.35    11.35         0.113462\n",
       "10            Linear   1      98.81    96.17         0.966872\n",
       "11            Linear   2      98.81    95.62         0.964467\n",
       "12            Linear   4      98.81    95.31         0.962138\n",
       "13            Linear   8      98.81    95.00         0.961116\n",
       "14            Linear  16      98.81    94.87         0.960150\n",
       "15  LinearUniformMix   1      98.69    95.80         0.962290\n",
       "16  LinearUniformMix   2      98.69    95.18         0.958389\n",
       "17  LinearUniformMix   4      98.69    94.56         0.955690\n",
       "18  LinearUniformMix   8      98.69    94.18         0.953208\n",
       "19  LinearUniformMix  16      98.69    93.99         0.951603\n",
       "20       Exponential   1      98.78    96.25         0.972100\n",
       "21       Exponential   2      98.78    95.84         0.969138\n",
       "22       Exponential   4      98.78    95.44         0.967560\n",
       "23       Exponential   8      98.78    95.07         0.965190\n",
       "24       Exponential  16      98.78    94.98         0.965058\n",
       "25            Cyclic   1      98.91    96.69         0.972485\n",
       "26            Cyclic   2      98.91    96.11         0.968564\n",
       "27            Cyclic   4      98.91    95.79         0.966761\n",
       "28            Cyclic   8      98.91    95.50         0.965473\n",
       "29            Cyclic  16      98.91    95.40         0.964958\n",
       "30            Random   1      11.35    11.35         0.112960\n",
       "31            Random   2      11.35    11.35         0.112960\n",
       "32            Random   4      11.35    11.35         0.112960\n",
       "33            Random   8      11.35    11.35         0.112960\n",
       "34            Random  16      11.35    11.35         0.112960"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation phase\n",
    "\n",
    "_, test_loader = get_data_loaders()\n",
    "strategies = [\"Vanilla\", \"Constant\", \"Linear\", \"LinearUniformMix\", \"Exponential\", \"Cyclic\", \"Random\"]\n",
    "model_dict = load_models(strategies, device)\n",
    "evaluate_strategies_on_attacks(model_dict, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optml)",
   "language": "python",
   "name": "optml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
