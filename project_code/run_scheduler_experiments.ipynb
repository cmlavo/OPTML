{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9352f19e-c4e2-419f-bdb7-6f63cce7cec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is the script we use to generate our schedulers clean accuracy, adversarial accuracy, runtime and others.\\nwe averaged multiple runs in our repport\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the script we use to generate our schedulers clean accuracy, adversarial accuracy, runtime and others.\n",
    "we averaged multiple runs in our repport\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f83a55b-b69b-4a32-9634-231fecd67395",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dbf237-9c79-4046-b08b-a00ccfdc2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..')))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import model.Models as Models\n",
    "import Defences as Defences\n",
    "import schedulers.Schedulers as Schedulers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Attacks import pgd_attack\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce2ffe6-51aa-4e92-9d35-1ff56de39b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndataset = \"CIFAR10\"\\nbatchsize = 200\\n\\nk_max = 7\\nepsilon = 255/8\\nepochs = 20\\nlr = 1e-3\\n\\ndef get_model():\\n    return Models.resnet18_cifar10().to(device) # See our Models.file, we also implemented ResNets and such\\n\\n\\ndef get_optimizer(model, lr = lr):\\n    return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hyper parameters, feel free to experiment.\n",
    "The commented ones are the ones we used on CIFAR10\n",
    "\"\"\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# MNIST SetUp ------------------------\n",
    "\n",
    "dataset = \"MNIST\" \n",
    "batchsize = 64 \n",
    "\n",
    "k_max = 20 \n",
    "epsilon = 0.3 \n",
    "epochs = 8 \n",
    "lr = 1e-3\n",
    "\n",
    "def get_model():\n",
    "    return Models.SmallConvNet().to(device) # See our Models.file, we also implemented ResNets and such\n",
    "\n",
    "def get_optimizer(model, lr = lr):\n",
    "    return torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# CIFAR SetUp ------------------------\n",
    "\n",
    "\"\"\"\n",
    "dataset = \"CIFAR10\"\n",
    "batchsize = 200\n",
    "\n",
    "k_max = 7\n",
    "epsilon = 255/8\n",
    "epochs = 20\n",
    "lr = 1e-3\n",
    "\n",
    "def get_model():\n",
    "    return Models.resnet18_cifar10().to(device) # See our Models.file, we also implemented ResNets and such\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr = lr):\n",
    "    return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1bd9405-cfaa-4d70-85eb-03334d8f66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size=64, dataset = dataset):\n",
    "    if dataset == \"MNIST\":\n",
    "        print(\"Loading MNIST data...\")\n",
    "        transform = transforms.ToTensor()\n",
    "        train_dataset = datasets.MNIST(root=\"../../project_code/data\", train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root=\"../../project_code/data\", train=False, download=True, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "        print(\"MNIST data loaded.\")\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    elif dataset == \"CIFAR10\":\n",
    "        \"\"\"Get CIFAR-10 data loaders with appropriate transforms\"\"\"\n",
    "        # CIFAR-10 specific transforms\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        \n",
    "        train_dataset = datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=transform_train)\n",
    "        test_dataset = datasets.CIFAR10(root=\"../data\", train=False, download=True, transform=transform_test)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=2)\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c888d02b-06d2-4627-91c6-26591efa2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on clean examples\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    test_loss /= test_total\n",
    "    test_acc = 100.0 * test_correct / test_total\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415d85d-6925-4388-9f54-fcb644f33983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_k_strategies(k_min=0, k_max=k_max, epsilon=epsilon, num_epochs=epochs, device=device, lr = lr, dataset = dataset):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(f\"Training on {device}\")\n",
    "    \n",
    "    train_loader, test_loader = get_data_loaders(dataset = dataset)\n",
    "    results = []\n",
    "    schedulers = {\n",
    "        \"Vanilla\": Schedulers.VanillaScheduler(),\n",
    "        \"Constant\": Schedulers.ConstantScheduler(k_min, k_max),\n",
    "        \"Linear\": Schedulers.LinearScheduler(k_min, k_max),\n",
    "        \"LinearUniformMix\": Schedulers.LinearUniformMixScheduler(k_min, k_max),\n",
    "        \"Cyclic\": Schedulers.CyclicScheduler(k_min, k_max),\n",
    "        \"Exponential\": Schedulers.ExponentialScheduler(k_min, k_max),\n",
    "        \"Random\": Schedulers.RandomScheduler(k_min, k_max),\n",
    "        \"Constant\": Schedulers.ConstantScheduler(k_min, k_max),\n",
    "    }\n",
    "    \n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    for name, scheduler in schedulers.items():\n",
    "        print(f\"\\nTraining with {name} scheduler...\")\n",
    "        \n",
    "        #model = Models.MediumConvNet().to(device)  # Using larger model\n",
    "        #optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        model = get_model()\n",
    "        optimizer = get_optimizer(model)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        Defences.train_with_adversarial_scheduler(\n",
    "            model, train_loader, test_loader, optimizer, criterion,\n",
    "            epsilon, scheduler, device, num_epochs=num_epochs, test_eval_rate=2, \n",
    "            clip_norm = 1, sched_lr = True\n",
    "        )\n",
    "        test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "        results.append({\n",
    "            \"strategy\": name,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy\": test_acc\n",
    "        })\n",
    "        # Save model after training\n",
    "        torch.save(model.state_dict(), f\"results/model_{name}.pth\")\n",
    "    # Save results to CSV\n",
    "    pd.DataFrame(results).to_csv(\"results/k_strategy_results.csv\", index=False)\n",
    "    print(\"\\nSummary of results:\")\n",
    "    print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28de5b19-18b0-4d1d-a6ed-e932a80fd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(strategies, device):\n",
    "    model_dict = {}\n",
    "    for name in strategies:\n",
    "        model = get_model()  \n",
    "        model.load_state_dict(torch.load(f\"results/model_{name}.pth\", map_location=device))\n",
    "        model.eval()\n",
    "        model_dict[name] = model\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def evaluate_strategies_on_attacks(model_dict, test_loader, device, epsilon=epsilon, k_list=[1,2,4,8,16]):\n",
    "    results = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for strategy, model in model_dict.items():\n",
    "        # Clean accuracy\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        clean_acc = 100.0 * correct / total\n",
    "\n",
    "        # Adversarial accuracy for each k\n",
    "        for k in k_list:\n",
    "            correct_adv = 0\n",
    "            total_adv = 0\n",
    "            confidences = []\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                adv_images, _ = pgd_attack(images, labels, model, criterion, epsilon, k, device)\n",
    "                outputs = model(adv_images)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_adv += labels.size(0)\n",
    "                correct_adv += (predicted == labels).sum().item()\n",
    "                # Mean confidence on correct predictions\n",
    "                for i in range(labels.size(0)):\n",
    "                    confidences.append(probs[i, predicted[i]].item())\n",
    "            adv_acc = 100.0 * correct_adv / total_adv\n",
    "            mean_conf = float(np.mean(confidences)) if confidences else 0.0\n",
    "            results.append({\n",
    "                \"strategy\": strategy,\n",
    "                \"k\": k,\n",
    "                \"clean_acc\": clean_acc,\n",
    "                \"adv_acc\": adv_acc,\n",
    "                \"mean_confidence\": mean_conf\n",
    "            })\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"results/adversarial_evaluation.csv\", index=False)\n",
    "    print(\"\\nAdversarial evaluation results:\")\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a668ef-efab-4546-b4c9-87ab0ab0a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Loading MNIST data...\n",
      "MNIST data loaded.\n",
      "\n",
      "Training with Vanilla scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.3349, Train Acc: 90.12%\n",
      "Epoch 2/8 | Train Loss: 0.0933, Train Acc: 97.09% | Test Loss: 0.0575, Test Acc: 98.15%\n",
      "Test Adv Loss (k=7): 13.1916, Test Adv Acc: 0.00%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 0.0631, Train Acc: 98.05%\n",
      "Epoch 4/8 | Train Loss: 0.0507, Train Acc: 98.43% | Test Loss: 0.0434, Test Acc: 98.42%\n",
      "Test Adv Loss (k=7): 16.1820, Test Adv Acc: 0.00%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 0.0420, Train Acc: 98.73%\n",
      "Epoch 6/8 | Train Loss: 0.0355, Train Acc: 98.93% | Test Loss: 0.0330, Test Acc: 98.86%\n",
      "Test Adv Loss (k=7): 18.2966, Test Adv Acc: 0.00%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 0.0301, Train Acc: 99.10%\n",
      "Epoch 8/8 | Train Loss: 0.0260, Train Acc: 99.26% | Test Loss: 0.0364, Test Acc: 98.84%\n",
      "Test Adv Loss (k=7): 19.8589, Test Adv Acc: 0.00%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 0 min 57.86 sec\n",
      "\n",
      "Training with Constant scheduler...\n",
      "Epoch 1/8 | Train Loss: 2.1321, Train Acc: 21.82%\n",
      "Epoch 2/8 | Train Loss: 1.8060, Train Acc: 32.89% | Test Loss: 1.4966, Test Acc: 40.98%\n",
      "Test Adv Loss (k=7): 1.7384, Test Adv Acc: 34.83%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 1.7154, Train Acc: 33.87%\n",
      "Epoch 4/8 | Train Loss: 1.6609, Train Acc: 34.49% | Test Loss: 1.3962, Test Acc: 48.56%\n",
      "Test Adv Loss (k=7): 1.6204, Test Adv Acc: 36.60%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 1.6165, Train Acc: 35.13%\n",
      "Epoch 6/8 | Train Loss: 1.5821, Train Acc: 35.32% | Test Loss: 1.3114, Test Acc: 48.87%\n",
      "Test Adv Loss (k=7): 1.5488, Test Adv Acc: 36.43%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 1.5585, Train Acc: 36.01%\n",
      "Epoch 8/8 | Train Loss: 1.5415, Train Acc: 36.26% | Test Loss: 1.2833, Test Acc: 51.28%\n",
      "Test Adv Loss (k=7): 1.5141, Test Adv Acc: 37.67%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 3 min 6.97 sec\n",
      "\n",
      "Training with Linear scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.3571, Train Acc: 89.23%\n",
      "Epoch 2/8 | Train Loss: 1.7222, Train Acc: 41.38% | Test Loss: 0.3518, Test Acc: 93.08%\n",
      "Test Adv Loss (k=7): 1.3587, Test Adv Acc: 49.81%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 1.1524, Train Acc: 59.23%\n",
      "Epoch 4/8 | Train Loss: 0.8103, Train Acc: 71.99% | Test Loss: 0.1562, Test Acc: 95.90%\n",
      "Test Adv Loss (k=7): 0.6515, Test Adv Acc: 78.09%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 0.6274, Train Acc: 78.96%\n",
      "Epoch 6/8 | Train Loss: 0.5668, Train Acc: 80.98% | Test Loss: 0.1303, Test Acc: 96.40%\n",
      "Test Adv Loss (k=7): 0.5168, Test Adv Acc: 82.93%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 0.5352, Train Acc: 82.14%\n",
      "Epoch 8/8 | Train Loss: 0.5047, Train Acc: 83.20% | Test Loss: 0.1203, Test Acc: 96.53%\n",
      "Test Adv Loss (k=7): 0.4628, Test Adv Acc: 84.74%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 1 min 52.08 sec\n",
      "\n",
      "Training with LinearUniformMix scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.3350, Train Acc: 89.92%\n",
      "Epoch 2/8 | Train Loss: 1.2335, Train Acc: 59.50% | Test Loss: 0.1221, Test Acc: 96.76%\n",
      "Test Adv Loss (k=7): 1.7748, Test Adv Acc: 37.87%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 1.0851, Train Acc: 62.49%\n",
      "Epoch 4/8 | Train Loss: 0.8569, Train Acc: 70.80% | Test Loss: 0.1483, Test Acc: 96.11%\n",
      "Test Adv Loss (k=7): 0.8383, Test Adv Acc: 71.13%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 0.6566, Train Acc: 78.09%\n",
      "Epoch 6/8 | Train Loss: 0.5198, Train Acc: 82.82% | Test Loss: 0.1281, Test Acc: 96.30%\n",
      "Test Adv Loss (k=7): 0.5636, Test Adv Acc: 81.13%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 0.4767, Train Acc: 84.10%\n",
      "Epoch 8/8 | Train Loss: 0.4544, Train Acc: 85.03% | Test Loss: 0.1181, Test Acc: 96.33%\n",
      "Test Adv Loss (k=7): 0.2896, Test Adv Acc: 90.80%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 1 min 26.30 sec\n",
      "\n",
      "Training with Cyclic scheduler...\n",
      "Epoch 1/8 | Train Loss: 1.1339, Train Acc: 61.56%\n",
      "Epoch 2/8 | Train Loss: 1.1769, Train Acc: 59.95% | Test Loss: 0.1848, Test Acc: 95.02%\n",
      "Test Adv Loss (k=7): 0.7766, Test Adv Acc: 74.16%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 0.7091, Train Acc: 76.17%\n",
      "Epoch 4/8 | Train Loss: 0.3701, Train Acc: 88.00% | Test Loss: 0.1098, Test Acc: 96.91%\n",
      "Test Adv Loss (k=7): 0.6027, Test Adv Acc: 79.31%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 0.5527, Train Acc: 81.65%\n",
      "Epoch 6/8 | Train Loss: 0.5256, Train Acc: 82.61% | Test Loss: 0.1186, Test Acc: 96.67%\n",
      "Test Adv Loss (k=7): 0.4991, Test Adv Acc: 83.32%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 0.4312, Train Acc: 85.95%\n",
      "Epoch 8/8 | Train Loss: 0.4623, Train Acc: 84.83% | Test Loss: 0.1117, Test Acc: 96.73%\n",
      "Test Adv Loss (k=7): 0.4708, Test Adv Acc: 84.64%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 1 min 54.44 sec\n",
      "\n",
      "Training with Exponential scheduler...\n",
      "Epoch 1/8 | Train Loss: 0.3345, Train Acc: 89.80%\n",
      "Epoch 2/8 | Train Loss: 0.0867, Train Acc: 97.29% | Test Loss: 0.0627, Test Acc: 97.86%\n",
      "Test Adv Loss (k=7): 11.4425, Test Adv Acc: 0.00%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 1.3550, Train Acc: 52.84%\n",
      "Epoch 4/8 | Train Loss: 1.0021, Train Acc: 64.94% | Test Loss: 0.1523, Test Acc: 96.42%\n",
      "Test Adv Loss (k=7): 0.9377, Test Adv Acc: 66.65%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 0.7686, Train Acc: 73.56%\n",
      "Epoch 6/8 | Train Loss: 0.6596, Train Acc: 77.27% | Test Loss: 0.1184, Test Acc: 96.73%\n",
      "Test Adv Loss (k=7): 0.6253, Test Adv Acc: 78.27%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 0.6234, Train Acc: 78.70%\n",
      "Epoch 8/8 | Train Loss: 0.6063, Train Acc: 79.36% | Test Loss: 0.1119, Test Acc: 96.84%\n",
      "Test Adv Loss (k=7): 0.5649, Test Adv Acc: 80.86%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 1 min 23.84 sec\n",
      "\n",
      "Training with Random scheduler...\n",
      "Epoch 1/8 | Train Loss: 2.3031, Train Acc: 10.71%\n",
      "Epoch 2/8 | Train Loss: 2.3013, Train Acc: 11.24% | Test Loss: 2.3011, Test Acc: 11.35%\n",
      "Test Adv Loss (k=7): 2.3011, Test Adv Acc: 11.35%\n",
      "Current LR: 0.000750\n",
      "Epoch 3/8 | Train Loss: 2.3013, Train Acc: 11.24%\n",
      "Epoch 4/8 | Train Loss: 2.1355, Train Acc: 19.84% | Test Loss: 0.8256, Test Acc: 75.95%\n",
      "Test Adv Loss (k=7): 1.5348, Test Adv Acc: 43.92%\n",
      "Current LR: 0.000500\n",
      "Epoch 5/8 | Train Loss: 1.2801, Train Acc: 53.70%\n",
      "Epoch 6/8 | Train Loss: 1.1062, Train Acc: 60.34% | Test Loss: 0.3812, Test Acc: 91.00%\n",
      "Test Adv Loss (k=7): 1.1122, Test Adv Acc: 60.33%\n",
      "Current LR: 0.000250\n",
      "Epoch 7/8 | Train Loss: 1.0427, Train Acc: 62.83%\n",
      "Epoch 8/8 | Train Loss: 0.9738, Train Acc: 65.50% | Test Loss: 0.3023, Test Acc: 93.01%\n",
      "Test Adv Loss (k=7): 0.9830, Test Adv Acc: 65.08%\n",
      "Current LR: 0.000000\n",
      "Training time (without eval): 2 min 1.01 sec\n",
      "\n",
      "Summary of results:\n",
      "           strategy  test_loss  test_accuracy\n",
      "0           Vanilla   0.036394          98.84\n",
      "1          Constant   1.283342          51.28\n",
      "2            Linear   0.120253          96.53\n",
      "3  LinearUniformMix   0.118100          96.33\n",
      "4            Cyclic   0.111675          96.73\n",
      "5       Exponential   0.111909          96.84\n",
      "6            Random   0.302286          93.01\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate results\n",
    "\"\"\"\n",
    "run_all_k_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1605691e-afcf-4146-b70f-56f18ef26bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data...\n",
      "MNIST data loaded.\n",
      "\n",
      "Adversarial evaluation results:\n",
      "            strategy   k  clean_acc  adv_acc  mean_confidence\n",
      "0            Vanilla   1      98.84     0.29         0.877280\n",
      "1            Vanilla   2      98.84     0.01         0.956656\n",
      "2            Vanilla   4      98.84     0.00         0.985394\n",
      "3            Vanilla   8      98.84     0.00         0.992300\n",
      "4            Vanilla  16      98.84     0.00         0.994804\n",
      "5           Constant   1      51.28    41.06         0.345403\n",
      "6           Constant   2      51.28    39.07         0.344707\n",
      "7           Constant   4      51.28    37.98         0.344060\n",
      "8           Constant   8      51.28    37.43         0.343125\n",
      "9           Constant  16      51.28    37.33         0.342866\n",
      "10            Linear   1      96.53    89.11         0.861458\n",
      "11            Linear   2      96.53    87.36         0.849682\n",
      "12            Linear   4      96.53    85.52         0.838642\n",
      "13            Linear   8      96.53    84.56         0.831179\n",
      "14            Linear  16      96.53    84.15         0.827354\n",
      "15  LinearUniformMix   1      96.33    93.40         0.914914\n",
      "16  LinearUniformMix   2      96.33    92.43         0.906111\n",
      "17  LinearUniformMix   4      96.33    91.19         0.896638\n",
      "18  LinearUniformMix   8      96.33    90.54         0.889556\n",
      "19  LinearUniformMix  16      96.33    90.33         0.887670\n",
      "20       Exponential   1      96.84    85.93         0.825606\n",
      "21       Exponential   2      96.84    83.90         0.812351\n",
      "22       Exponential   4      96.84    81.96         0.801059\n",
      "23       Exponential   8      96.84    80.52         0.793635\n",
      "24       Exponential  16      96.84    79.64         0.790684\n",
      "25            Cyclic   1      96.73    88.42         0.868067\n",
      "26            Cyclic   2      96.73    87.01         0.857087\n",
      "27            Cyclic   4      96.73    85.29         0.847172\n",
      "28            Cyclic   8      96.73    84.47         0.839463\n",
      "29            Cyclic  16      96.73    83.82         0.835781\n",
      "30            Random   1      93.01    72.10         0.660634\n",
      "31            Random   2      93.01    69.11         0.650911\n",
      "32            Random   4      93.01    66.47         0.642148\n",
      "33            Random   8      93.01    65.39         0.637467\n",
      "34            Random  16      93.01    64.26         0.635387\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>k</th>\n",
       "      <th>clean_acc</th>\n",
       "      <th>adv_acc</th>\n",
       "      <th>mean_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1</td>\n",
       "      <td>98.84</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.877280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>2</td>\n",
       "      <td>98.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.956656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>4</td>\n",
       "      <td>98.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.985394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>8</td>\n",
       "      <td>98.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>16</td>\n",
       "      <td>98.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.994804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Constant</td>\n",
       "      <td>1</td>\n",
       "      <td>51.28</td>\n",
       "      <td>41.06</td>\n",
       "      <td>0.345403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Constant</td>\n",
       "      <td>2</td>\n",
       "      <td>51.28</td>\n",
       "      <td>39.07</td>\n",
       "      <td>0.344707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Constant</td>\n",
       "      <td>4</td>\n",
       "      <td>51.28</td>\n",
       "      <td>37.98</td>\n",
       "      <td>0.344060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Constant</td>\n",
       "      <td>8</td>\n",
       "      <td>51.28</td>\n",
       "      <td>37.43</td>\n",
       "      <td>0.343125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Constant</td>\n",
       "      <td>16</td>\n",
       "      <td>51.28</td>\n",
       "      <td>37.33</td>\n",
       "      <td>0.342866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear</td>\n",
       "      <td>1</td>\n",
       "      <td>96.53</td>\n",
       "      <td>89.11</td>\n",
       "      <td>0.861458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear</td>\n",
       "      <td>2</td>\n",
       "      <td>96.53</td>\n",
       "      <td>87.36</td>\n",
       "      <td>0.849682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear</td>\n",
       "      <td>4</td>\n",
       "      <td>96.53</td>\n",
       "      <td>85.52</td>\n",
       "      <td>0.838642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Linear</td>\n",
       "      <td>8</td>\n",
       "      <td>96.53</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.831179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Linear</td>\n",
       "      <td>16</td>\n",
       "      <td>96.53</td>\n",
       "      <td>84.15</td>\n",
       "      <td>0.827354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>1</td>\n",
       "      <td>96.33</td>\n",
       "      <td>93.40</td>\n",
       "      <td>0.914914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>2</td>\n",
       "      <td>96.33</td>\n",
       "      <td>92.43</td>\n",
       "      <td>0.906111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>4</td>\n",
       "      <td>96.33</td>\n",
       "      <td>91.19</td>\n",
       "      <td>0.896638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>8</td>\n",
       "      <td>96.33</td>\n",
       "      <td>90.54</td>\n",
       "      <td>0.889556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearUniformMix</td>\n",
       "      <td>16</td>\n",
       "      <td>96.33</td>\n",
       "      <td>90.33</td>\n",
       "      <td>0.887670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>1</td>\n",
       "      <td>96.84</td>\n",
       "      <td>85.93</td>\n",
       "      <td>0.825606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>96.84</td>\n",
       "      <td>83.90</td>\n",
       "      <td>0.812351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>96.84</td>\n",
       "      <td>81.96</td>\n",
       "      <td>0.801059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>8</td>\n",
       "      <td>96.84</td>\n",
       "      <td>80.52</td>\n",
       "      <td>0.793635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Exponential</td>\n",
       "      <td>16</td>\n",
       "      <td>96.84</td>\n",
       "      <td>79.64</td>\n",
       "      <td>0.790684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>1</td>\n",
       "      <td>96.73</td>\n",
       "      <td>88.42</td>\n",
       "      <td>0.868067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>2</td>\n",
       "      <td>96.73</td>\n",
       "      <td>87.01</td>\n",
       "      <td>0.857087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>4</td>\n",
       "      <td>96.73</td>\n",
       "      <td>85.29</td>\n",
       "      <td>0.847172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>8</td>\n",
       "      <td>96.73</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.839463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cyclic</td>\n",
       "      <td>16</td>\n",
       "      <td>96.73</td>\n",
       "      <td>83.82</td>\n",
       "      <td>0.835781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>93.01</td>\n",
       "      <td>72.10</td>\n",
       "      <td>0.660634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Random</td>\n",
       "      <td>2</td>\n",
       "      <td>93.01</td>\n",
       "      <td>69.11</td>\n",
       "      <td>0.650911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Random</td>\n",
       "      <td>4</td>\n",
       "      <td>93.01</td>\n",
       "      <td>66.47</td>\n",
       "      <td>0.642148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random</td>\n",
       "      <td>8</td>\n",
       "      <td>93.01</td>\n",
       "      <td>65.39</td>\n",
       "      <td>0.637467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Random</td>\n",
       "      <td>16</td>\n",
       "      <td>93.01</td>\n",
       "      <td>64.26</td>\n",
       "      <td>0.635387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            strategy   k  clean_acc  adv_acc  mean_confidence\n",
       "0            Vanilla   1      98.84     0.29         0.877280\n",
       "1            Vanilla   2      98.84     0.01         0.956656\n",
       "2            Vanilla   4      98.84     0.00         0.985394\n",
       "3            Vanilla   8      98.84     0.00         0.992300\n",
       "4            Vanilla  16      98.84     0.00         0.994804\n",
       "5           Constant   1      51.28    41.06         0.345403\n",
       "6           Constant   2      51.28    39.07         0.344707\n",
       "7           Constant   4      51.28    37.98         0.344060\n",
       "8           Constant   8      51.28    37.43         0.343125\n",
       "9           Constant  16      51.28    37.33         0.342866\n",
       "10            Linear   1      96.53    89.11         0.861458\n",
       "11            Linear   2      96.53    87.36         0.849682\n",
       "12            Linear   4      96.53    85.52         0.838642\n",
       "13            Linear   8      96.53    84.56         0.831179\n",
       "14            Linear  16      96.53    84.15         0.827354\n",
       "15  LinearUniformMix   1      96.33    93.40         0.914914\n",
       "16  LinearUniformMix   2      96.33    92.43         0.906111\n",
       "17  LinearUniformMix   4      96.33    91.19         0.896638\n",
       "18  LinearUniformMix   8      96.33    90.54         0.889556\n",
       "19  LinearUniformMix  16      96.33    90.33         0.887670\n",
       "20       Exponential   1      96.84    85.93         0.825606\n",
       "21       Exponential   2      96.84    83.90         0.812351\n",
       "22       Exponential   4      96.84    81.96         0.801059\n",
       "23       Exponential   8      96.84    80.52         0.793635\n",
       "24       Exponential  16      96.84    79.64         0.790684\n",
       "25            Cyclic   1      96.73    88.42         0.868067\n",
       "26            Cyclic   2      96.73    87.01         0.857087\n",
       "27            Cyclic   4      96.73    85.29         0.847172\n",
       "28            Cyclic   8      96.73    84.47         0.839463\n",
       "29            Cyclic  16      96.73    83.82         0.835781\n",
       "30            Random   1      93.01    72.10         0.660634\n",
       "31            Random   2      93.01    69.11         0.650911\n",
       "32            Random   4      93.01    66.47         0.642148\n",
       "33            Random   8      93.01    65.39         0.637467\n",
       "34            Random  16      93.01    64.26         0.635387"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation phase\n",
    "\n",
    "_, test_loader = get_data_loaders()\n",
    "strategies = [\"Vanilla\", \"Constant\", \"Linear\", \"LinearUniformMix\", \"Exponential\", \"Cyclic\", \"Random\"]\n",
    "#strategies = [\"Vanilla\", \"LinearUniformMix\", \"Cyclic\"]\n",
    "model_dict = load_models(strategies, device)\n",
    "evaluate_strategies_on_attacks(model_dict, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (optml)",
   "language": "python",
   "name": "optml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
