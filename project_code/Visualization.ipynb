{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8373b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages, and classes adapted from decision boundary visualization studies\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import Models\n",
    "import Attacks\n",
    "import Tools\n",
    "from ssnp import SSNP, visualize_decision_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb80b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MNIST dataset from online\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), \"../data\"))\n",
    "MNIST_data = datasets.MNIST(root=data_dir, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# pre-select adversarial examples\n",
    "ADVERSARIAL_BATCH_N = 200\n",
    "SEED = 42  # For reproducibility\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random_indices = torch.randint(0, MNIST_data.data.shape[0], (ADVERSARIAL_BATCH_N,))\n",
    "\n",
    "adversarial_images = MNIST_data.data[random_indices].float()\n",
    "adversarial_labels = MNIST_data.targets[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MNIST classifier model\n",
    "MODEL_SETTING = \"small\"\n",
    "\n",
    "if MODEL_SETTING == \"small\":\n",
    "    # Use SmallConvNet for MNIST classification\n",
    "    MNIST_model = Models.SmallConvNet()\n",
    "elif MODEL_SETTING == \"normal\":\n",
    "    # Use ConvNet for MNIST classification\n",
    "    MNIST_model = Models.ConvNet()\n",
    "\n",
    "device_torch = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \n",
    "    \"cuda\" if torch.cuda.is_available() else \n",
    "    \"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ad87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all trained models to produce adversarial examples\n",
    "#MODELS = [\"Constant\", \"Cyclic\", \"Exponential\", \"Linear\", \"LinearUniformMix\", \"Random\"]\n",
    "MODELS = [\"Cyclic\", \"Exponential\", \"Linear\", \"LinearUniformMix\"]\n",
    "#MODELS = [\"Constant\"]\n",
    "MODEL_REPO_ID = \"JulienStal/MNIST-SmallConvs-AdversarialSchedulers\"\n",
    "EPSILON = 0.3\n",
    "K = 10\n",
    "BATCH_SIZE = 10000\n",
    "EPOCHS = 200\n",
    "PATIENCE = 50\n",
    "\n",
    "SAVE_SSNP_HF = False\n",
    "SSNP_REPO_ID = \"JulienStal/SSNPs\"\n",
    "\n",
    "ssnps = []\n",
    "im_grids = []\n",
    "prob_grids = []\n",
    "dbms = []\n",
    "models = []\n",
    "pts_arr = []\n",
    "\n",
    "for model in MODELS:\n",
    "    # Import the model weights from HuggingFace\n",
    "    model_name = f\"{MODEL_SETTING}_conv_{model}\"\n",
    "    model_file_name = f\"model_{model}.pth\"    \n",
    "    local_pth_path = hf_hub_download(repo_id=MODEL_REPO_ID, filename=model_file_name, force_download=True)    \n",
    "    MNIST_model.load_state_dict(torch.load(local_pth_path, map_location=device_torch))\n",
    "\n",
    "    for idx, (image, label) in enumerate(zip(adversarial_images, adversarial_labels)):\n",
    "        if image.dim() == 2: image = image.unsqueeze(0).unsqueeze(0)\n",
    "        elif image.dim() == 3: image = image.unsqueeze(0)\n",
    "        label = torch.tensor([label])  # Make label a batch\n",
    "\n",
    "        adv_image, perturbation = Attacks.pgd_attack(image, label, MNIST_model, nn.CrossEntropyLoss(), EPSILON, K, device_torch)\n",
    "        adversarial_images[idx] = adv_image.squeeze()\n",
    "\n",
    "    # Generate visualization\n",
    "    ssnp_model_path = os.path.abspath(os.path.join(os.getcwd(), \"../models/ssnp\", f\"ssnp_{model}\"))\n",
    "    \n",
    "    ssnp, im_grid, prob_grid, dbm, pts = visualize_decision_boundaries(\n",
    "        original_dataset = MNIST_data,\n",
    "        dataset_name = \"MNIST\",\n",
    "        classifier_model = MNIST_model,\n",
    "        classifier_model_name = model_name,\n",
    "        ssnp_path_and_name = ssnp_model_path,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        adversarial_images=adversarial_images,\n",
    "        ssnp_training_epochs = EPOCHS,\n",
    "        ssnp_training_patience = PATIENCE,\n",
    "        verbose = False,\n",
    "    )\n",
    "\n",
    "    ssnps.append(ssnp)\n",
    "    im_grids.append(im_grid)\n",
    "    prob_grids.append(prob_grid)\n",
    "    dbms.append(dbm)\n",
    "    models.append(MNIST_model)\n",
    "    pts_arr.append(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the synthetic image for a given pixel\n",
    "PIXEL_X, PIXEL_Y = (150, 150) # vertical and horizontal\n",
    "index = PIXEL_X*300 + PIXEL_Y\n",
    "\n",
    "ssnp = ssnps[0]\n",
    "img_grid = im_grids[0]\n",
    "prob_grid = prob_grids[0]\n",
    "dbm = dbms[0]\n",
    "model = models[0]\n",
    "pts = pts_arr[0]\n",
    "\n",
    "# Set pixel to red in the dbm and display\n",
    "dbm.putpixel((PIXEL_Y, PIXEL_X), (255, 0, 0))  # Set pixel to red\n",
    "display(dbm)\n",
    "\n",
    "# Points values of the pixel\n",
    "pt = pts[index]\n",
    "\n",
    "# Get the synthetic image for the given pixel and print it\n",
    "synthetic_img = torch.tensor(ssnp.inverse_transform(torch.tensor(pt).unsqueeze(0))).view(1, 1, 28, 28)\n",
    "label_tensor = torch.tensor(img_grid[PIXEL_X][PIXEL_Y]).view(1,1)\n",
    "\n",
    "# Print the label of the synthetic image\n",
    "print(f\"Label of synthetic image at pixel ({PIXEL_X}, {PIXEL_Y}): {label_tensor.item()} (confidence {prob_grid[PIXEL_X][PIXEL_Y]:.2f})\")\n",
    "\n",
    "Tools.plot_predictions(model, synthetic_img, label_tensor, device_torch, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPTML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
