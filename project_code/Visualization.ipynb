{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8373b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clavo\\miniconda3\\envs\\OPTML_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary packages, and classes adapted from decision boundary visualization studies\n",
    "\n",
    "from huggingface_hub import hf_hub_download, HfApi\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil\n",
    "\n",
    "import model.Models as Models\n",
    "from ssnp import visualize_decision_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATIONS FOR THE VISUALIZATION SCRIPT\n",
    "\n",
    "SEED = 42  # For reproducibility\n",
    "\n",
    "IMPORT_SSNP_MODEL = True   # If True, the SSNP model is imported from HuggingFace and saved locally. If false, trains from scratch.\n",
    "SSNP_REPO_ID = \"cmlavo/SSNP\"    # HuggingFace repo ID for the SSNP model (make sure your token has access this)\n",
    "SSNP_MODEL_FILENAME = \"ssnp_MNIST.keras\"    # Filename to load/save the SSNP model locally\n",
    "SAVE_SSNP_HF = True     # If True, saves the trained SSNP model to HuggingFace (requires write access to the repo)\n",
    "\n",
    "MODEL_SETTING = \"medium\" # \"small\" for SmallConvNet, \"medium\" for MediumConvNet\n",
    "# The models to visualize decision boundaries for (list is complete, remove entries as desired)\n",
    "#   Note: there is no \"Vanilla\" model for the SmallConvNet, may encounter an error if configured as such\n",
    "MODELS = [\"Vanilla\", \"Constant\", \"Cyclic\", \"Exponential\", \"Linear\", \"LinearUniformMix\", \"Random\"]\n",
    "BATCH_SIZE = 10000  # Batch size for the data classifier inference step (specify based on available memory)\n",
    "EPOCHS = 300        # Number of epochs to train the SSNP model (if training from scratch)\n",
    "PATIENCE = 100      # Early stopping patience\n",
    "SHOW_POINTS = False # If True, highlights the MNIST points in the decision boundary visualization\n",
    "NAME_SUFFIX = \"\"    # Optional suffix for the saved image file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb80b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MNIST dataset from online\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), \"../data\"))\n",
    "MNIST_data = datasets.MNIST(root=data_dir, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MNIST classifier model\n",
    "\n",
    "if MODEL_SETTING == \"small\":\n",
    "    # Use SmallConvNet for MNIST classification\n",
    "    MNIST_model = Models.SmallConvNet()\n",
    "    model_repo_id = \"JulienStal/MNIST-SmallConvs-AdversarialSchedulers\"\n",
    "elif MODEL_SETTING == \"medium\":\n",
    "    # Use ConvNet for MNIST classification\n",
    "    MNIST_model = Models.MediumConvNet()\n",
    "    model_repo_id = \"JulienStal/MNIST-MediumConvs-AdversarialSchedulers\"\n",
    "\n",
    "device_torch = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \n",
    "    \"cuda\" if torch.cuda.is_available() else \n",
    "    \"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a77a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SSNP pre-trained model weights from HuggingFace\n",
    "local_path = os.path.abspath(os.path.join(os.getcwd(), \"../models/ssnp\", SSNP_MODEL_FILENAME))\n",
    "\n",
    "if IMPORT_SSNP_MODEL:    \n",
    "    cached_path = hf_hub_download(repo_id=SSNP_REPO_ID, filename=SSNP_MODEL_FILENAME)    \n",
    "    shutil.copy(cached_path, local_path)\n",
    "    print(f\"Model saved to {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ad87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all trained models to produce adversarial examples\n",
    "\n",
    "ssnps = []\n",
    "im_grids = []\n",
    "prob_grids = []\n",
    "dbms = []\n",
    "models = []\n",
    "pts_arr = []\n",
    "\n",
    "for model in MODELS:\n",
    "    # Import the model weights from HuggingFace\n",
    "    model_name = f\"{MODEL_SETTING}_conv_{model}\"\n",
    "    model_file_name = f\"model_{model}.pth\"    \n",
    "    local_pth_path = hf_hub_download(repo_id=model_repo_id, filename=model_file_name, force_download=False)    \n",
    "    MNIST_model.load_state_dict(torch.load(local_pth_path, map_location=device_torch))\n",
    "\n",
    "    # Generate visualization\n",
    "    ssnp, im_grid, prob_grid, dbm, pts = visualize_decision_boundaries(\n",
    "        original_dataset = MNIST_data,\n",
    "        dataset_name = \"MNIST\",\n",
    "        classifier_model = MNIST_model,\n",
    "        classifier_model_name = model_name,\n",
    "        ssnp_path_and_name = local_path,\n",
    "        image_name_suffix = NAME_SUFFIX,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        ssnp_training_epochs = EPOCHS,\n",
    "        ssnp_training_patience = PATIENCE,\n",
    "        show_points = SHOW_POINTS,\n",
    "        verbose = True,\n",
    "    )\n",
    "\n",
    "    ssnps.append(ssnp)\n",
    "    im_grids.append(im_grid)\n",
    "    prob_grids.append(prob_grid)\n",
    "    dbms.append(dbm)\n",
    "    models.append(MNIST_model)\n",
    "    pts_arr.append(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46536da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SSNP .keras model to HuggingFace\n",
    "\n",
    "if SAVE_SSNP_HF:\n",
    "    api = HfApi()\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=local_path,\n",
    "        path_in_repo=\"ssnp_MNIST.keras\",\n",
    "        repo_id=SSNP_REPO_ID,\n",
    "        repo_type=\"model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the synthetic image for a given pixel\n",
    "PIXEL_X, PIXEL_Y = (148, 143) # vertical and horizontal pixel coordinates in the decision boundary visualization grid\n",
    "MODEL_TO_VISUALIZE = \"Vanilla\" # Name of the model in MODELS to visualize\n",
    "\n",
    "model_index = MODELS.index(MODEL_TO_VISUALIZE)\n",
    "index = PIXEL_X*300 + PIXEL_Y\n",
    "ssnp = ssnps[0]\n",
    "img_grid = im_grids[0]\n",
    "prob_grid = prob_grids[0]\n",
    "dbm = dbms[0]\n",
    "model = models[0]\n",
    "pts = pts_arr[0]\n",
    "\n",
    "# Set pixel to red in the dbm and display\n",
    "dbm.putpixel((PIXEL_Y, PIXEL_X), (255, 0, 0))  # Set pixel to red\n",
    "print(\"Reference DBM with the pixel highlighted red:\")\n",
    "display(dbm)\n",
    "\n",
    "# Points values of the pixel\n",
    "pt = pts[index]\n",
    "\n",
    "# Get the synthetic image for the given pixel and print it\n",
    "synthetic_img = torch.tensor(ssnp.inverse_transform(torch.tensor(pt).unsqueeze(0))).view(1, 1, 28, 28)\n",
    "label_tensor = torch.tensor(img_grid[PIXEL_X][PIXEL_Y]).view(1,1)\n",
    "\n",
    "# Print the label of the synthetic image\n",
    "print(f\"Label of synthetic image at pixel ({PIXEL_X}, {PIXEL_Y}): {label_tensor.item()} (confidence {prob_grid[PIXEL_X][PIXEL_Y]:.2f})\")\n",
    "\n",
    "plt.imshow(synthetic_img[0].squeeze().cpu(), cmap='gray')\n",
    "plt.axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPTML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
